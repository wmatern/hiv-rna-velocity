{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA Velocity Analysis of scRNAseq data from HIV infected CD4+ Tcells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence data is from: PMID 30282021. In summary the authors compared HIV-infected versus uninfected CD4+ T-cells from 2 donors in a 8-12 week in vitro model using 10X Chromium V2. The goal was to simulate HIV latency and describe the transcriptomic landscape of the HIV latent reservoir.\n",
    "\n",
    "Samples used are  the following:\n",
    "1. SRR6825024 - Donor 1, Infected\n",
    "2. SRR6825025 - Donor 2, Infected\n",
    "3. SRR6825026 - Donor 1, Uninfected\n",
    "4. SRR6825027 - Donor 2, Uninfected\n",
    "\n",
    "This notebook processes the data after mapping to the combined human/HIV transcriptome. I took the following steps to generate raw count data (external to this notebook):\n",
    "\n",
    "1. The genome sequence for NL43-D6-dreGFP (synthetic strain of HIV containing GFP) was appended to the human transcriptome (GRCh38).\n",
    "2. \"unspliced\" transcripts were appended to the transcriptome.\n",
    "3. The salmon index was created using the entire human genome as a decoy sequence. Used an r5.xlarge on AWS.\n",
    "4. Mapping was performed with alevin for all 4 samples. Used a c5.12xlarge.\n",
    "5. Downloaded data to local for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages for using R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: SummarizedExperiment\n",
      "\n",
      "R[write to console]: Loading required package: GenomicRanges\n",
      "\n",
      "R[write to console]: Loading required package: stats4\n",
      "\n",
      "R[write to console]: Loading required package: BiocGenerics\n",
      "\n",
      "R[write to console]: Loading required package: parallel\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'BiocGenerics'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:parallel':\n",
      "\n",
      "    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,\n",
      "    clusterExport, clusterMap, parApply, parCapply, parLapply,\n",
      "    parLapplyLB, parRapply, parSapply, parSapplyLB\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:stats':\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:base':\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\n",
      "    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\n",
      "    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\n",
      "    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\n",
      "    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\n",
      "    union, unique, unsplit, which, which.max, which.min\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: S4Vectors\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'S4Vectors'\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:base':\n",
      "\n",
      "    expand.grid\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: IRanges\n",
      "\n",
      "R[write to console]: Loading required package: GenomeInfoDb\n",
      "\n",
      "R[write to console]: Loading required package: Biobase\n",
      "\n",
      "R[write to console]: Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: DelayedArray\n",
      "\n",
      "R[write to console]: Loading required package: matrixStats\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'matrixStats'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:Biobase':\n",
      "\n",
      "    anyMissing, rowMedians\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'DelayedArray'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:matrixStats':\n",
      "\n",
      "    colMaxs, colMins, colRanges, rowMaxs, rowMins, rowRanges\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:base':\n",
      "\n",
      "    aperm, apply, rowsum\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#Load Necessary Packages\n",
    "library(tximeta)\n",
    "library(SingleCellExperiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this next section once for each sample and change the \"key\" each time\n",
    "Data is dumped to a python pickle for fast reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: importing quantifications\n",
      "\n",
      "R[write to console]: reading in alevin gene-level counts across cells with fishpond\n",
      "\n",
      "R[write to console]: couldn't find matching transcriptome, returning non-ranged SummarizedExperiment\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 41989094\n",
      "[1] 26061958\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#### Note: Slow (~5min / sample) - only run once per sample\n",
    "\n",
    "#Load data from alevin format using tximeta\n",
    "key = \"SRR6825027\" #Set sample name here: c('SRR6825024','SRR6825025','SRR6825026','SRR6825027')\n",
    "txi <- tximeta::tximeta(coldata = data.frame(\n",
    "  names = key,\n",
    "  files = paste0(\"input/\", key, \"/alevin/quants_mat.gz\"), \n",
    "  stringsAsFactors = FALSE\n",
    "), type = \"alevin\")\n",
    "\n",
    "## Split the unspliced and spliced counts into two \"assays\" in the object\n",
    "cg <- read.delim(\"input/for_tximeta/combined_transcript.spliced_to_unspliced.tsv\",\n",
    "                 header = TRUE, as.is = TRUE)\n",
    "\n",
    "# This next line splits unspliced and spliced transcript counts - \n",
    "# if either spliced or unspliced are missing then add a zero.\n",
    "txis <- splitSE(txi, cg, assayName = \"counts\")\n",
    "\n",
    "#Store in sce object for conversion to anndata (Python)\n",
    "txis_sce <- as(txis, \"SingleCellExperiment\")\n",
    "assays(txis_sce) <- list(\n",
    "    counts = assay(txis_sce, \"spliced\"),\n",
    "    spliced = assay(txis_sce, \"spliced\"),\n",
    "    unspliced = assay(txis_sce, \"unspliced\")\n",
    ")\n",
    "\n",
    "print(sum(assay(txis_sce, \"spliced\")))\n",
    "print(sum(assay(txis_sce, \"unspliced\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import R objects into Python\n",
    "import anndata\n",
    "import anndata2ri\n",
    "from rpy2.robjects import r\n",
    "import pickle\n",
    "\n",
    "anndata2ri.activate()\n",
    "adata = r('txis_sce')\n",
    "\n",
    "# Dump to pickle - for fast loading later\n",
    "key = r('key')[0]\n",
    "with open('processed_data/'+key+'_adata_raw.pickle', 'wb') as fp:\n",
    "    pickle.dump(adata,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create trimmed version of raw files for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import scanpy as sc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scvelo as scv\n",
    "import anndata\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Setup for plotting\n",
    "matplotlib.use('AGG')\n",
    "scv.settings.set_figure_params('scvelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load samples into memory\n",
    "adict = {}\n",
    "for samp, key in zip(['SRR6825024','SRR6825025','SRR6825026','SRR6825027'], ['d1i','d2i','d1u','d2u']):\n",
    "    with open('processed_data/'+samp+'_adata_raw.pickle', 'rb') as fp:\n",
    "        adict[key] = pickle.load(fp)\n",
    "    \n",
    "    # Remove calculated values when present\n",
    "    adict[key].uns = {}\n",
    "    try:\n",
    "        adict[key].obsm.pop('X_pca')\n",
    "        adict[key].obsm.pop('X_tsne')\n",
    "        adict[key].layers.pop('logcounts')\n",
    "        adict[key].obs.drop(['sizeFactor'],axis=1,inplace=True)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the read counts before trimming\n",
    "def plot_readcount_pretrim(adict, key):\n",
    "    logcounts = np.log10((adict[key].layers['spliced'] + adict[key].layers['unspliced']).sum(axis=1))\n",
    "    y = sorted(logcounts.tolist(),reverse=True)\n",
    "    x = range(len(y))\n",
    "    plt.figure()\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('Barcode (Cell) Rank')\n",
    "    plt.ylabel('log10[readcount] (spliced + unspliced)')\n",
    "    plt.savefig('figures/QC/'+key+'_readcount_pretrim.png')\n",
    "    \n",
    "plot_readcount_pretrim(adict, 'd1i')\n",
    "plot_readcount_pretrim(adict, 'd1u')\n",
    "plot_readcount_pretrim(adict, 'd2i')\n",
    "plot_readcount_pretrim(adict, 'd2u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim (likely) doublets and empty cells. Cutoffs chosen manually\n",
    "def trim_cells(adict,key,min_lcount,max_lcount):\n",
    "    \n",
    "    #Trim cells\n",
    "    logcounts = np.log10((adict[key].layers['spliced'] + adict[key].layers['unspliced']).sum(axis=1))\n",
    "    adict[key] = adict[key][(logcounts > min_lcount) & (logcounts < max_lcount), :]\n",
    "\n",
    "    logcounts = np.log10((adict[key].layers['spliced'] + adict[key].layers['unspliced']).sum(axis=1))\n",
    "    y = sorted(logcounts.tolist(),reverse=True)\n",
    "    x = range(len(y))\n",
    "    plt.figure()\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('Barcode (Cell) Rank')\n",
    "    plt.ylabel('log10[readcount] (spliced + unspliced)')\n",
    "    plt.savefig('figures/QC/'+key+'_readcount_posttrim.png')\n",
    "    \n",
    "trim_cells(adict,'d1i', 0, 10) #No trimming\n",
    "trim_cells(adict,'d1u', 0, 10) #No trimming\n",
    "trim_cells(adict,'d2i', 2.8, 3.8)\n",
    "trim_cells(adict,'d2u', 3.0, 4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot read counts by gene\n",
    "def plot_readcount_gene(adict,key):\n",
    "    temp = (adict[key].layers['spliced'])\n",
    "    counts = temp.sum(axis=0).tolist()[0]\n",
    "    logcounts = np.log10(temp.sum(axis=0) + 0.1).tolist()[0]\n",
    "    y = sorted(logcounts,reverse=True)\n",
    "    x = range(len(y))\n",
    "    plt.figure()\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('Gene Index')\n",
    "    plt.ylabel('log10[readcount] (spliced)')\n",
    "    plt.savefig('figures/QC/'+key+'_readcount_pergene_spliced')\n",
    "\n",
    "plot_readcount_gene(adict,'d1u')\n",
    "plot_readcount_gene(adict,'d1i')\n",
    "plot_readcount_gene(adict,'d2u')\n",
    "plot_readcount_gene(adict,'d2i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 45693 genes that are detected in less than 20 cells (spliced).\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`\n",
      "Filtered out 45124 genes that are detected in less than 20 cells (spliced).\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`\n",
      "Filtered out 45706 genes that are detected in less than 20 cells (spliced).\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`\n",
      "Filtered out 48787 genes that are detected in less than 20 cells (spliced).\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`\n"
     ]
    }
   ],
   "source": [
    "#Trim genes by choose a subset that is good quality in all samples\n",
    "temp_d1u = scv.pp.filter_genes(adict['d1u'], min_cells = 20, copy=True)\n",
    "temp_d1u = scv.pp.filter_genes_dispersion(temp_d1u, n_top_genes=20000, copy=True)\n",
    "\n",
    "temp_d1i = scv.pp.filter_genes(adict['d1i'], min_cells = 20, copy=True)\n",
    "temp_d1i = scv.pp.filter_genes_dispersion(temp_d1i, n_top_genes=20000, copy=True)\n",
    "\n",
    "temp_d2u = scv.pp.filter_genes(adict['d2u'], min_cells = 20, copy=True)\n",
    "temp_d2u = scv.pp.filter_genes_dispersion(temp_d2u, n_top_genes=20000, copy=True)\n",
    "\n",
    "temp_d2i = scv.pp.filter_genes(adict['d2i'], min_cells = 20, copy=True)\n",
    "temp_d2i = scv.pp.filter_genes_dispersion(temp_d2i, n_top_genes=20000, copy=True)\n",
    "\n",
    "#Take intersection of genes that pass filter and add genes of interest\n",
    "genes_of_interest = ['NL43.g','ENSG00000167286.9', 'ENSG00000198851.10', 'ENSG00000160654.11']\n",
    "gene_pf = (temp_d1i.var.index & temp_d1u.var.index & temp_d2u.var.index & temp_d2i.var.index) #TODO: You should only use these for the velocity fit\n",
    "gene_keep = gene_pf.union(pd.Index(genes_of_interest))\n",
    "\n",
    "#Note: The approach of restricting to the intersection will tend to yield a small number of cells with identical values. These are NOT duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of genes detected after subsetting\n",
    "def plot_genes_detected(adata,key,gene_keep,min_count):\n",
    "    n_genes_detected = np.squeeze((adict[key][:,gene_keep].layers['spliced'] >= min_count).A.sum(axis=1))\n",
    "    \n",
    "    y = sorted(n_genes_detected,reverse=True)\n",
    "    x = range(len(y))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('Barcode (Cell) Rank')\n",
    "    plt.ylabel('# Genes Detected')\n",
    "    plt.savefig('figures/QC/'+key+'_genes_detected_posttrim.png')\n",
    "    \n",
    "plot_genes_detected(adict,'d1i',gene_keep,1)\n",
    "plot_genes_detected(adict,'d1u',gene_keep,1)\n",
    "plot_genes_detected(adict,'d2i',gene_keep,1)\n",
    "plot_genes_detected(adict,'d2u',gene_keep,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge individual anndata objects and write out\n",
    "trim_ls = []\n",
    "for key in ['d1u','d1i','d2u','d2i']:\n",
    "    trim_ls.append(adict[key][:,gene_keep])\n",
    "adata_merged = trim_ls[0].concatenate(trim_ls[1:4],uns_merge=None, batch_key='group', batch_categories=['d1u','d1i','d2u','d2i'])\n",
    "adata_merged.write('processed_data/merged_adata_trimmed.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export trimmed data including all genes\n",
    "for key in ['d1u','d1i','d2u','d2i']:\n",
    "    adict[key][:,gene_keep].write('processed_data/'+key+'_adata_trimmed.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooled Sample Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 24645 × 11160\n",
      "    obs: 'group'\n",
      "    layers: 'spliced', 'unspliced'\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "adata = anndata.read_h5ad('processed_data/merged_adata_trimmed.h5ad')\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abundance of ['spliced', 'unspliced']: [0.68 0.32]\n",
      "\n",
      "\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "computing neighbors\n",
      "    finished (0:00:10) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "\n",
      "\n",
      "AnnData object with n_obs × n_vars = 24645 × 11160\n",
      "    obs: 'group', 'n_counts'\n",
      "    var: 'gene_count_corr'\n",
      "    uns: 'log1p', 'pca', 'neighbors', 'umap'\n",
      "    obsm: 'X_pca', 'X_umap'\n",
      "    varm: 'PCs'\n",
      "    layers: 'spliced', 'unspliced'\n",
      "    obsp: 'distances', 'connectivities'\n"
     ]
    }
   ],
   "source": [
    "# Print fraction of spliced/unspliced\n",
    "scv.utils.show_proportions(adata)\n",
    "print('\\n')\n",
    "# Compute various useful values\n",
    "scv.pp.normalize_per_cell(adata, counts_per_cell_after = 10**6, enforce=True)\n",
    "sc.pp.log1p(adata, base=10)\n",
    "scv.pp.neighbors(adata)\n",
    "scv.tl.umap(adata)\n",
    "print('\\n')\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: saving figure to file figures/umap_merged_B2M.png\n",
      "WARNING: saving figure to file figures/umap_merged_CD3d.png\n",
      "WARNING: saving figure to file figures/umap_merged_HIV.png\n",
      "WARNING: saving figure to file figures/umap_merged_group.png\n"
     ]
    }
   ],
   "source": [
    "sc.pl.umap(adata, save='_merged_B2M.png', color='ENSG00000166710.20', title='B2M')\n",
    "sc.pl.umap(adata, save='_merged_CD3d.png', color='ENSG00000167286.9', title='CD3d')\n",
    "sc.pl.umap(adata, save='_merged_HIV.png', color='NL43.g', title='HIV')\n",
    "sc.pl.umap(adata, save='_merged_group.png', color='group', title='Donor and Infection Effects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual sample analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this section: choose a condition to run the velocity analysis by setting the variable \"key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abundance of ['spliced', 'unspliced']: [0.73 0.27]\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "computing neighbors\n",
      "    finished (0:00:02) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:05) --> added \n",
      "    'Ms' and 'Mu', moments of spliced/unspliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:03) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing velocity graph\n",
      "    finished (0:00:31) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "Abundance of ['spliced', 'unspliced']: [0.68 0.32]\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "computing neighbors\n",
      "    finished (0:00:00) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:04) --> added \n",
      "    'Ms' and 'Mu', moments of spliced/unspliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:03) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing velocity graph\n",
      "    finished (0:00:34) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "Abundance of ['spliced', 'unspliced']: [0.66 0.34]\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "computing neighbors\n",
      "    finished (0:00:10) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:18) --> added \n",
      "    'Ms' and 'Mu', moments of spliced/unspliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:10) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing velocity graph\n",
      "    finished (0:03:01) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "Abundance of ['spliced', 'unspliced']: [0.69 0.31]\n",
      "Normalized count data: X, spliced, unspliced.\n",
      "computing neighbors\n",
      "    finished (0:00:05) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:11) --> added \n",
      "    'Ms' and 'Mu', moments of spliced/unspliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:14) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing velocity graph\n",
      "    finished (0:05:30) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "for key in ['d1i', 'd1u', 'd2u', 'd2i']: #Choose conditions for analysis here: ['d1u','d1i','d2u','d2i']\n",
    "    #Read in data\n",
    "    adata = anndata.read_h5ad('processed_data/'+key+'_adata_trimmed.h5ad')\n",
    "\n",
    "    # Print fraction of spliced/unspliced\n",
    "    scv.utils.show_proportions(adata)\n",
    "    # Compute various useful values\n",
    "    scv.pp.normalize_per_cell(adata, counts_per_cell_after = 10**6, enforce=True)\n",
    "    sc.pp.log1p(adata,base=10)\n",
    "    scv.pp.moments(adata, n_pcs = 30, n_neighbors = 30)\n",
    "    scv.tl.umap(adata)\n",
    "\n",
    "    #Compute velocities for each gene\n",
    "    scv.tl.velocity(adata, mode = 'stochastic')\n",
    "\n",
    "    #Ensure HIV expression is NOT used for velocity calculation\n",
    "    gene_list_bool = adata.var.velocity_genes.copy()\n",
    "    gene_list_bool['NL43.g'] = False\n",
    "    gene_subset = adata.var_names[adata.var.velocity_genes]\n",
    "\n",
    "    #Compute Cosine correlations\n",
    "    scv.tl.velocity_graph(adata,gene_subset = gene_subset)\n",
    "\n",
    "    adata.write('processed_data/'+key+'_adata_plots.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing velocity embedding\n",
      "    finished (0:00:01) --> added\n",
      "    'velocity_pca', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d1i_HIV_pca.png\n",
      "saving figure to file ./figures/scvelo_d1i_CD3d_pca.png\n",
      "saving figure to file ./figures/scvelo_d1i_B2M_pca.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:00) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d1i_HIV_umap.png\n",
      "saving figure to file ./figures/scvelo_d1i_CD3d_umap.png\n",
      "saving figure to file ./figures/scvelo_d1i_B2M_umap.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:00) --> added\n",
      "    'velocity_pca', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d1u_HIV_pca.png\n",
      "saving figure to file ./figures/scvelo_d1u_CD3d_pca.png\n",
      "saving figure to file ./figures/scvelo_d1u_B2M_pca.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:00) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d1u_HIV_umap.png\n",
      "saving figure to file ./figures/scvelo_d1u_CD3d_umap.png\n",
      "saving figure to file ./figures/scvelo_d1u_B2M_umap.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:06) --> added\n",
      "    'velocity_pca', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d2u_HIV_pca.png\n",
      "saving figure to file ./figures/scvelo_d2u_CD3d_pca.png\n",
      "saving figure to file ./figures/scvelo_d2u_B2M_pca.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:03) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d2u_HIV_umap.png\n",
      "saving figure to file ./figures/scvelo_d2u_CD3d_umap.png\n",
      "saving figure to file ./figures/scvelo_d2u_B2M_umap.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:04) --> added\n",
      "    'velocity_pca', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d2i_HIV_pca.png\n",
      "saving figure to file ./figures/scvelo_d2i_CD3d_pca.png\n",
      "saving figure to file ./figures/scvelo_d2i_B2M_pca.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:02) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d2i_HIV_umap.png\n",
      "saving figure to file ./figures/scvelo_d2i_CD3d_umap.png\n",
      "saving figure to file ./figures/scvelo_d2i_B2M_umap.png\n"
     ]
    }
   ],
   "source": [
    "for key in ['d1i', 'd1u', 'd2u', 'd2i']:\n",
    "    adata = anndata.read_h5ad('processed_data/'+key+'_adata_plots.h5ad')\n",
    "\n",
    "    scv.pl.velocity_embedding_stream(adata, basis='pca', save=key+'_HIV_pca.png', color='NL43.g', frameon=True, title='HIV')\n",
    "    scv.pl.velocity_embedding_stream(adata, basis='pca', save=key+'_CD3d_pca.png', color='ENSG00000167286.9', frameon=True, title='CD3d')\n",
    "    scv.pl.velocity_embedding_stream(adata, basis='pca', save=key+'_B2M_pca.png', color='ENSG00000166710.20', frameon=True, title='B2M') #Beta_2 Microglobulin\n",
    "\n",
    "    scv.pl.velocity_embedding_stream(adata, basis = 'umap', save=key+'_HIV_umap.png', color='NL43.g', frameon=True, title='HIV')\n",
    "    scv.pl.velocity_embedding_stream(adata, basis = 'umap', save=key+'_CD3d_umap.png', color='ENSG00000167286.9', frameon=True, title='CD3d')\n",
    "    scv.pl.velocity_embedding_stream(adata, basis = 'umap', save=key+'_B2M_umap.png', color='ENSG00000166710.20', frameon=True, title='B2M') #Beta_2 Microglobulin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of expression for closer inspection\n",
    "for key in ['d1i', 'd1u', 'd2u', 'd2i']:\n",
    "    gene = 'ENSG00000166710.20' #Beta 2 microglobulin has an odd distribution in most samples - Can cells lose expression of B2M/MHC-1?\n",
    "    hgnc = 'B2M'\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(adata[:, gene].X.A.squeeze(),bins=50)\n",
    "    plt.savefig('figures/hist_'+key+'_'+hgnc+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing velocity embedding\n",
      "    finished (0:00:00) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d1i_clusters_umap.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:00) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d1u_clusters_umap.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:03) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d2u_clusters_umap.png\n",
      "computing velocity embedding\n",
      "    finished (0:00:02) --> added\n",
      "    'velocity_umap', embedded velocity vectors (adata.obsm)\n",
      "saving figure to file ./figures/scvelo_d2i_clusters_umap.png\n"
     ]
    }
   ],
   "source": [
    "for key in ['d1i', 'd1u', 'd2u', 'd2i']:\n",
    "    adata = anndata.read_h5ad('processed_data/'+key+'_adata_plots.h5ad')\n",
    "    scv.tl.louvain(adata)\n",
    "    scv.pl.velocity_embedding_stream(adata, basis = 'umap', save=key+'_clusters_umap.png', frameon=True, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
